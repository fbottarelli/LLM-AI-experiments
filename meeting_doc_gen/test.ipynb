{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New working directory: /home/fd/repo/AI/generativeai\n"
     ]
    }
   ],
   "source": [
    "# modifica al path del progetto\n",
    "import os\n",
    "# Modifica il percorso di lavoro se necessario\n",
    "os.chdir('..')\n",
    "# Stampa di nuovo il percorso di lavoro per conferma\n",
    "print(\"New working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load env\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "# TODO(developer): Update and un-comment below line\n",
    "project_id = \"geminitesting-432015\"\n",
    "location = \"europe-west1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a plate of blueberry scones with a cup of coffee and a bowl of blueberries. It looks like a delicious and inviting breakfast or brunch spread.\n"
     ]
    }
   ],
   "source": [
    "# TODO(developer): Update and un-comment below line\n",
    "# project_id = \"PROJECT_ID\"\n",
    "\n",
    "vertexai.init(project=project_id, location=location)\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "\n",
    "response = model.generate_content(\n",
    "    [\n",
    "        Part.from_uri(\n",
    "            \"gs://cloud-samples-data/generative-ai/image/scones.jpg\",\n",
    "            mime_type=\"image/jpeg\",\n",
    "        ),\n",
    "        \"What is shown in this image?\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIdeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens: 9139\n",
      "total_billable_characters: 471\n",
      "\n",
      "<speaker>Person1</speaker>: Ok, provo a parlare.\n",
      "<speaker>Person2</speaker>: Ok, va bene. Proviamo a dirci qualcosina.\n",
      "<speaker>Person1</speaker>: Sì, così registro, che ho dimenticato di registrare quella di prima, ovviamente.\n",
      "<speaker>Person2</speaker>: Ah, giusto.\n",
      "<speaker>Person1</speaker>: Così dopo provo anche con questo, l'unico motivo per cui ti ho chiesto questi 5 minuti, però era anche per cogliere l'occasione, no, eh, perché, dato che ci sono le ferie, se possiamo proprio in 5 minuti ricapitolare un attimo la situazione.\n",
      "<speaker>Person2</speaker>: Ok, va bene.\n",
      "<speaker>Person1</speaker>: Perché sto facendo un po' di confusione.\n",
      "<speaker>Person2</speaker>: E in generale o dei Patch Spring?\n",
      "<speaker>Person1</speaker>: No, no, sì, in generale, proprio su la I generativa, I e tutta quella, così.\n",
      "<speaker>Person2</speaker>: Bene.\n",
      "<speaker>Person1</speaker>: Eh, adesso mi scrivo un piccolo documento, magari poi lo metto in uno spazio di analytics, però va bene, è più per ordine mio mentale, non per Perché c'è un documento necessario adesso.\n",
      "<speaker>Person2</speaker>: Eh, allora, vabbè, Special Spring adesso, giusto per così mi scrivo due cosine.\n",
      "<speaker>Person1</speaker>: Ok.\n",
      "<speaker>Person2</speaker>: Adesso mettere le immagini che sembra che loro vogliono.\n",
      "<speaker>Person1</speaker>: Sì, già ci sono delle domande.\n",
      "<speaker>Person2</speaker>: Sì, eh, nel caso ho pensato appunto che si può fare tranquillamente usando appunto le funzionalità Vision dei vari modelli e magari bisognerebbe avere una strategia, diciamo, adesso, partendo da unificare una strategia, no, per estrarre le informazioni dai cataloghi. Cioè, per esempio, prendiamo un catalogo, prendiamo una pagina alla volta, la trasformiamo in un'immagine e riuscire a estrarre tutto, cioè, testo, tabelle, eventuali immagini, tutto in un unico passaggio, in modo da avere la costruzione unica e più pulita delle informazioni, soprattutto che si adatti meglio, secondo me, anche a diversi cataloghi e eventualmente diversi tipologie di documenti, cioè cercare di renderla un po' più generale possibile.\n",
      "<speaker>Person1</speaker>: Sì, sì, sì, capito. Ok, quindi mettere le immagini e pianificare.\n",
      "<speaker>Person2</speaker>: Ok.\n",
      "<speaker>Person1</speaker>: Eh, l'unico altro passaggio è quello di eh riuscire a estrarre i dati anche dalle altre tabelle di quel catalogo lì.\n",
      "<speaker>Person2</speaker>: Eh, ok, sì. Poi eventualmente faccio il backlog nei vari spazi e li metto lì, giusto, tanto per farne uno.\n",
      "<speaker>Person1</speaker>: Sì, vabbè. Io sapevo che metterò le issues, ma facciamo come facciamo sempre così. Io farei sempre, sì, esatto, almeno per me è utilissimo avere anche il backlog scritto, mi è molto utile. Estrarre le tabelle diverse.\n",
      "<speaker>Person2</speaker>: Mh, mh.\n",
      "<speaker>Person1</speaker>: E anche qui, magari provare da strategia, cioè vedere, va bene, adesso, sì qua, per esempio, esatto, non abbiamo Gemini Google, immagino non si possa chiedere, però, magari al ritorno delle vacanze, eh, valutare, no, se proporlo.\n",
      "<speaker>Person2</speaker>: Eh, devo parlare con Maurizio per capire come fare quel discorso lì perché non so come si faccia, come si può giocare, e se non ci sono solo le loro reazioni.\n",
      "<speaker>Person1</speaker>: Non si può, come si fa.\n",
      "<speaker>Person2</speaker>: Perché, no, cioè, cioè nel senso, non so perché noi arriviamo lì con una soluzione, gli ho spiegato che varia il che varia molto questo metodo qui, però non so se loro vanno bene ad aprire un altro contratto con un'altra cosa, non tanto perché costa di più, perché comunque se togli Bedrock, eh, non del tutto, perché, beh, forse sì.\n",
      "<speaker>Person1</speaker>: Eh, vabbè, ti costa di meno probabilmente.\n",
      "<speaker>Person2</speaker>: Sì, ti costa anche di meno di, anche se usiamo modelli come GPT-4 Mini, o appunto eh Gemini 1.5 Flash, eh, ci costa sicuramente meno. Devo capire solo come, tecnicamente, perché, cioè se fosse una roba così, ammicizia, io correrei senza problemi, però sì perché comunque, cioè, con questi siamo partiti in questo modo e va bene, con i prossimi non partiremo più in questo modo. Però volevo capire se potevamo, in un attimo, raddrizzare la situazione anche qui. Ci sarà sicuramente da fare un passaggio con qualcuno di legale per capire.\n",
      "<speaker>Person1</speaker>: Assolutamente, sì. Adesso me lo sono scritto anche questo.\n",
      "<speaker>Person2</speaker>: I dati.\n",
      "<speaker>Person1</speaker>: Ok, così. Perfetto, va bene, questo giusto perché mi piacerebbe usarlo già perché ho già le idee. Nel senso, perché se vogliamo appunto generalizzare già, potremmo sfruttare questa cosa. Però, vabbè, io ti farò, mi sono segnato di fare, di capire con lui e eventualmente fare l'RDA per chiedere l'acquisto di un un account e una chiave per fare le chiamate API di Google, va bene.\n",
      "<speaker>Person2</speaker>: Sì, no, quello ci sta, direi che, quello non penso sia un problema, nel senso.\n",
      "<speaker>Person1</speaker>: Almeno, vabbè, quello che costa, cioè, nel senso, eh poi costa la chiamata, nel senso, eh, cioè nel senso, poi capisci, cioè, se lo danno a me, tipo \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "# TODO(developer): Update and un-comment below lines\n",
    "# project_id = \"PROJECT_ID\"\n",
    "\n",
    "vertexai.init(project=project_id, location=location)\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "You will be given a audio from a Google Meet. Your task is to extract the dialogue and format it as a conversation between two speakers, labeled as \"Person1\" and \"Person2\".\n",
    "\n",
    "Follow these guidelines to extract and format the dialogue:\n",
    "1. Identify the two main speakers in the conversation.\n",
    "2. Label the first speaker who talks as \"Person1\" and the second speaker as \"Person2\".\n",
    "3. Format each line of dialogue as follows:\n",
    "   <speaker>Person1/Person2</speaker>: [Their dialogue]\n",
    "4. Start a new line for each change in speaker.\n",
    "5. the language of the dialogue is Italian.\n",
    "\"\"\"\n",
    "\n",
    "audio_file_path = \"meeting_doc_gen/media/audio/output_cutted.mp3\"\n",
    "\n",
    "# Read the audio file in binary mode\n",
    "with open(audio_file_path, \"rb\") as audio_file:\n",
    "    audio_bytes = audio_file.read()\n",
    "\n",
    "audio_part = Part.from_data(audio_bytes, mime_type=\"audio/mp3\")\n",
    "\n",
    "contents = [audio_part, prompt]\n",
    "\n",
    "# Counts tokens\n",
    "print(model.count_tokens(contents))\n",
    "response = model.generate_content(contents)\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (data: bytes, mime_type: str) -> 'Part'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "dir(Part)\n",
    "inspect.signature(Part.from_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_clean_text = \"\"\"\n",
    "You are tasked with cleaning a conversation transcript. The transcript contains speaker labels and informal speech patterns. Your goal is to produce a cleaner, more readable version of the conversation while preserving its essential content.\n",
    "\n",
    "Here is the conversation transcript to clean:\n",
    "\n",
    "<conversation_transcript>\n",
    "{{CONVERSATION_TRANSCRIPT}}\n",
    "</conversation_transcript>\n",
    "\n",
    "Follow these steps to clean the text:\n",
    "\n",
    "1. Remove speaker labels (e.g., <speaker>Person1</speaker>:).\n",
    "2. Eliminate filler words and sounds (e.g., \"Eh\", \"Mh\", \"vabbè\", \"cioè\").\n",
    "3. Remove repetitions and false starts.\n",
    "4. Correct any obvious grammatical errors.\n",
    "5. Simplify overly complex sentences while maintaining the original meaning.\n",
    "6. Ensure the text flows naturally from one statement to the next.\n",
    "\n",
    "Format your output as follows:\n",
    "- Present the cleaned text as a continuous paragraph without line breaks.\n",
    "- Use proper capitalization and punctuation.\n",
    "- Preserve the general order of ideas from the original conversation.\n",
    "\n",
    "Provide your cleaned version of the conversation inside <cleaned_text> tags.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
